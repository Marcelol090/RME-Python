#!/usr/bin/env python3
"""
ast_auto_split.py

AST-based auto-split script:
- Finds large files (threshold)
- Extracts top-level classes/functions exceeding node length OR complexity
- Dry-run by default; --apply to write files with backups
"""

from __future__ import annotations

import ast
from pathlib import Path

from radon.complexity import cc_visit

MAX_FILE_LINES = 700
MAX_NODE_LINES = 150
MAX_COMPLEXITY = 10


def read_lines(path: Path):
    return path.read_text(encoding="utf-8").splitlines()


def node_len(node):
    return (
        (getattr(node, "end_lineno", None) or getattr(node, "lineno", None)) - node.lineno + 1
        if hasattr(node, "lineno") and hasattr(node, "end_lineno")
        else 0
    )


def node_complexity(node, lines):
    try:
        start = node.lineno - 1
        end = node.end_lineno
        snippet = "\n".join(lines[start:end])
        blocks = cc_visit(snippet)
        if not blocks:
            return 0
        return max(getattr(b, "complexity", 0) for b in blocks)
    except Exception:
        return 0


def process_file(path: Path, apply: bool, threshold_override: int | None = None):
    lines = read_lines(path)
    threshold = threshold_override or MAX_FILE_LINES
    if len(lines) < threshold:
        return

    try:
        tree = ast.parse("\n".join(lines))
    except SyntaxError:
        print(f"Skipping (syntax error): {path}")
        return

    imports = []
    for node in tree.body:
        if isinstance(node, (ast.Import, ast.ImportFrom)):
            s = node.lineno - 1
            e = getattr(node, "end_lineno", s + 1)
            imports.extend(lines[s:e])

    remaining = lines.copy()
    extracted = []

    for node in tree.body:
        if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):
            ln = node_len(node)
            comp = node_complexity(node, lines)
            if ln >= MAX_NODE_LINES or comp > MAX_COMPLEXITY:
                name = getattr(node, "name", "anon")
                start = node.lineno - 1
                end = node.end_lineno
                snippet = lines[start:end]
                new_name = f"{path.stem}_{name.lower()}.py"
                new_path = path.parent / new_name
                extracted.append((name, new_path, snippet))
                for i in range(start, end):
                    remaining[i] = ""

    if not extracted:
        return

    print(f"\nCandidate: {path} ({len(lines)} lines)")
    for name, new_path, _ in extracted:
        print(f"  -> propose: {name} -> {new_path.name}")

    if not apply:
        return

    # backup
    backup = path.with_suffix(path.suffix + ".bak")
    backup.write_text("\n".join(lines), encoding="utf-8")

    # write extracted modules
    for name, new_path, snippet in extracted:
        content = "# AUTO-GENERATED by ast_auto_split\n\n"
        if imports:
            content += "\n".join(imports) + "\n\n"
        content += "\n".join(snippet) + "\n"
        new_path.write_text(content, encoding="utf-8")

    # rewrite original
    import_lines = [f"from .{p.stem} import {nm}" for nm, p, _ in extracted]
    final = []
    if imports:
        final.extend(imports)
        final.append("")
    final.extend(import_lines)
    final.append("")
    final.extend([l for l in remaining if l.strip()])
    path.write_text("\n".join(final), encoding="utf-8")
    print(f"Applied split: backup {backup.name}")
